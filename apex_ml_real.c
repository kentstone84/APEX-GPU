// apex_ml_real.c - APEX with REAL ML Model
#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <dlfcn.h>
#include <time.h>

#include "apex_ml_model.h"

// Type definitions
typedef int CUresult;
typedef int cudaError_t;
typedef void* CUdevice;
typedef void* CUfunction;
typedef void* CUstream;
typedef void* cudaStream_t;
typedef unsigned long long CUdeviceptr;

typedef struct {
    unsigned int x, y, z;
} dim3;

#define CUDA_SUCCESS 0
#define cudaSuccess 0

// GPU Configuration (RTX 5080)
#define RTX5080_SM_COUNT 84
#define RTX5080_MAX_THREADS_PER_SM 1536
#define RTX5080_MAX_BLOCKS_PER_SM 16

// Global state
static void *real_driver = NULL;
static void *real_runtime = NULL;
static unsigned long kernel_launches = 0;
static unsigned long ml_predictions_made = 0;
static double total_prediction_time_us = 0.0;

// Performance tracking
static double get_time_us() {
    struct timespec ts;
    clock_gettime(CLOCK_MONOTONIC, &ts);
    return ts.tv_sec * 1000000.0 + ts.tv_nsec / 1000.0;
}

// Generate optimization recommendations
static void generate_recommendations(unsigned int gx, unsigned int gy, unsigned int gz,
                                     unsigned int bx, unsigned int by, unsigned int bz,
                                     size_t shared_mem,
                                     MLModelOutput *pred,
                                     char *hint, size_t hint_size) {
    unsigned int threads_per_block = bx * by * bz;
    unsigned long long total_blocks = (unsigned long long)gx * gy * gz;
    
    // Rule 1: Block size too small
    if (threads_per_block < 64) {
        snprintf(hint, hint_size,
                "âš ï¸  CRITICAL: Block size too small (%u threads)\n"
                "â•‘    â†’ Increase to 128-256 threads for %dx better occupancy\n"
                "â•‘    â†’ Current warp efficiency: %.1f%%",
                threads_per_block, threads_per_block < 32 ? 8 : 4,
                (threads_per_block / 32.0f) * 100.0f);
        return;
    }
    
    // Rule 2: Block size too large
    if (threads_per_block > 768) {
        snprintf(hint, hint_size,
                "âš ï¸  WARNING: Block size very large (%u threads)\n"
                "â•‘    â†’ Consider reducing to 256-512 for better SM utilization\n"
                "â•‘    â†’ Large blocks may limit active warps per SM",
                threads_per_block);
        return;
    }
    
    // Rule 3: Insufficient blocks for GPU
    if (total_blocks < RTX5080_SM_COUNT) {
        snprintf(hint, hint_size,
                "âš ï¸  UNDERUTILIZATION: Only %llu blocks for %d SMs\n"
                "â•‘    â†’ Increase grid size to at least %d blocks\n"
                "â•‘    â†’ Current SM utilization: %.1f%%",
                total_blocks, RTX5080_SM_COUNT, RTX5080_SM_COUNT * 2,
                (total_blocks / (float)RTX5080_SM_COUNT) * 100.0f);
        return;
    }
    
    // Rule 4: Good occupancy but can be optimized
    if (pred->occupancy > 0.7f && pred->occupancy < 0.95f) {
        snprintf(hint, hint_size,
                "âœ“ GOOD configuration (%.1f%% occupancy)\n"
                "â•‘    â†’ Minor optimization: Try block size %u for 100%% occupancy",
                pred->occupancy * 100.0f,
                threads_per_block < 256 ? 256 : (threads_per_block > 256 ? 256 : 256));
        return;
    }
    
    // Rule 5: Excellent configuration
    if (pred->occupancy >= 0.95f) {
        snprintf(hint, hint_size,
                "âœ… EXCELLENT configuration!\n"
                "â•‘    â†’ Occupancy: %.1f%% (near-optimal)\n"
                "â•‘    â†’ SM utilization: %.1f%%",
                pred->occupancy * 100.0f,
                pred->sm_utilization * 100.0f);
        return;
    }
    
    // Default
    snprintf(hint, hint_size,
            "ğŸ’¡ Occupancy: %.1f%% - Consider tuning block size",
            pred->occupancy * 100.0f);
}

// Main ML prediction and logging
static void log_ml_prediction(unsigned int launch_num,
                              unsigned int gx, unsigned int gy, unsigned int gz,
                              unsigned int bx, unsigned int by, unsigned int bz,
                              size_t shared_mem) {
    // Run ML model
    double start_time = get_time_us();
    MLModelOutput pred = predict_with_ml(gx, gy, gz, bx, by, bz, shared_mem);
    double end_time = get_time_us();
    double prediction_time = end_time - start_time;
    
    total_prediction_time_us += prediction_time;
    ml_predictions_made++;
    
    // Calculate derived metrics
    unsigned long long total_threads = (unsigned long long)gx * gy * gz * bx * by * bz;
    unsigned long long total_blocks = (unsigned long long)gx * gy * gz;
    unsigned int threads_per_block = bx * by * bz;
    
    // Estimate SM assignment
    unsigned int blocks_per_sm = (total_blocks + RTX5080_SM_COUNT - 1) / RTX5080_SM_COUNT;
    unsigned int active_sms = total_blocks >= RTX5080_SM_COUNT ? 
                              RTX5080_SM_COUNT : 
                              (unsigned int)total_blocks;
    
    // Generate optimization hint
    char optimization_hint[512];
    generate_recommendations(gx, gy, gz, bx, by, bz, shared_mem,
                            &pred, optimization_hint, sizeof(optimization_hint));
    
    // Display results
    fprintf(stderr, "\n");
    fprintf(stderr, "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n");
    fprintf(stderr, "â•‘  ğŸ§  APEX NEURAL NETWORK - Kernel #%-3u                       â•‘\n", launch_num);
    fprintf(stderr, "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n");
    fprintf(stderr, "â•‘  ğŸ“Š KERNEL CONFIGURATION                                      â•‘\n");
    fprintf(stderr, "â•‘    Grid:             (%u, %u, %u) = %llu blocks\n", 
            gx, gy, gz, total_blocks);
    fprintf(stderr, "â•‘    Block:            (%u, %u, %u) = %u threads/block\n",
            bx, by, bz, threads_per_block);
    fprintf(stderr, "â•‘    Total Threads:    %llu\n", total_threads);
    fprintf(stderr, "â•‘    Shared Memory:    %zu bytes\n", shared_mem);
    fprintf(stderr, "â•‘                                                               â•‘\n");
    fprintf(stderr, "â•‘  ğŸ¤– NEURAL NETWORK PREDICTIONS                                â•‘\n");
    fprintf(stderr, "â•‘    GPU Occupancy:    %.1f%% (NN output: %.4f)\n", 
            pred.occupancy * 100.0f, pred.occupancy);
    fprintf(stderr, "â•‘    Est. Time:        %.3f ms\n", pred.execution_time_ms);
    fprintf(stderr, "â•‘    SM Utilization:   %.1f%% (%u / %d SMs active)\n",
            pred.sm_utilization * 100.0f, active_sms, RTX5080_SM_COUNT);
    fprintf(stderr, "â•‘    Block Efficiency: %.1f%%\n", pred.block_efficiency * 100.0f);
    fprintf(stderr, "â•‘    Blocks per SM:    %u\n", blocks_per_sm);
    fprintf(stderr, "â•‘                                                               â•‘\n");
    fprintf(stderr, "â•‘  âš¡ PERFORMANCE METRICS                                       â•‘\n");
    fprintf(stderr, "â•‘    Warp Count:       %u warps/block\n", (threads_per_block + 31) / 32);
    fprintf(stderr, "â•‘    Warp Efficiency:  %.1f%%\n",
            ((threads_per_block % 32 == 0) ? 100.0f : 
             (threads_per_block % 32) / 32.0f * 100.0f));
    fprintf(stderr, "â•‘    Prediction Time:  %.2f Î¼s\n", prediction_time);
    fprintf(stderr, "â•‘                                                               â•‘\n");
    fprintf(stderr, "â•‘  ğŸ’¡ ML OPTIMIZATION RECOMMENDATION                            â•‘\n");
    fprintf(stderr, "â•‘    %s\n", optimization_hint);
    fprintf(stderr, "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
}

__attribute__((constructor))
void apex_init(void) {
    fprintf(stderr, "\n");
    fprintf(stderr, "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n");
    fprintf(stderr, "â•‘       ğŸ§  APEX NEURAL NETWORK SCHEDULER v4.0                  â•‘\n");
    fprintf(stderr, "â•‘          Real-time ML Kernel Optimization                     â•‘\n");
    fprintf(stderr, "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    real_driver = dlopen("/usr/lib/wsl/lib/libcuda.so.1.1", RTLD_LAZY);
    real_runtime = dlopen("libcudart.so", RTLD_LAZY);
    
    if (real_driver) fprintf(stderr, "  âœ“ Driver API loaded\n");
    if (real_runtime) fprintf(stderr, "  âœ“ Runtime API loaded\n");
    fprintf(stderr, "  âœ“ Neural Network: 3-layer FFN (8â†’16â†’8â†’4)\n");
    fprintf(stderr, "  âœ“ Model Parameters: ~400 weights + biases\n");
    fprintf(stderr, "  âœ“ Target GPU: RTX 5080 (84 SMs, 1536 threads/SM)\n");
    fprintf(stderr, "\n");
}

__attribute__((destructor))
void apex_cleanup(void) {
    fprintf(stderr, "\n");
    fprintf(stderr, "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n");
    fprintf(stderr, "â•‘              APEX NEURAL NETWORK SESSION SUMMARY              â•‘\n");
    fprintf(stderr, "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n");
    fprintf(stderr, "â•‘  Kernels Launched:      %-38lu â•‘\n", kernel_launches);
    fprintf(stderr, "â•‘  ML Predictions Made:   %-38lu â•‘\n", ml_predictions_made);
    
    if (ml_predictions_made > 0) {
        double avg_prediction_time = total_prediction_time_us / ml_predictions_made;
        fprintf(stderr, "â•‘  Avg Prediction Time:   %.2f Î¼s%-30s â•‘\n", 
                avg_prediction_time, "");
        fprintf(stderr, "â•‘  Total ML Overhead:     %.2f ms%-29s â•‘\n",
                total_prediction_time_us / 1000.0, "");
    }
    
    fprintf(stderr, "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    fprintf(stderr, "\n");
}

// ============================================================================
// DRIVER API
// ============================================================================

CUresult cuInit(unsigned int Flags) {
    typedef CUresult (*T)(unsigned int);
    T real = (T)dlsym(real_driver, "cuInit");
    return real(Flags);
}

CUresult cuDeviceGet(CUdevice *device, int ordinal) {
    typedef CUresult (*T)(CUdevice*, int);
    T real = (T)dlsym(real_driver, "cuDeviceGet");
    return real(device, ordinal);
}

CUresult cuMemAlloc_v2(CUdeviceptr *dptr, size_t size) {
    typedef CUresult (*T)(CUdeviceptr*, size_t);
    T real = (T)dlsym(real_driver, "cuMemAlloc_v2");
    return real(dptr, size);
}

CUresult cuLaunchKernel(CUfunction f, unsigned int gx, unsigned int gy, unsigned int gz,
                        unsigned int bx, unsigned int by, unsigned int bz,
                        unsigned int shared, CUstream stream, void **params, void **extra) {
    typedef CUresult (*T)(CUfunction, unsigned int, unsigned int, unsigned int,
                          unsigned int, unsigned int, unsigned int, unsigned int,
                          CUstream, void**, void**);
    T real = (T)dlsym(real_driver, "cuLaunchKernel");
    
    kernel_launches++;
    log_ml_prediction(kernel_launches, gx, gy, gz, bx, by, bz, shared);
    
    return real(f, gx, gy, gz, bx, by, bz, shared, stream, params, extra);
}

// ============================================================================
// RUNTIME API
// ============================================================================

cudaError_t __cudaPushCallConfiguration(dim3 gridDim, dim3 blockDim,
                                        size_t sharedMem, cudaStream_t stream) {
    typedef cudaError_t (*T)(dim3, dim3, size_t, cudaStream_t);
    static T real = NULL;
    if (!real) real = (T)dlsym(RTLD_NEXT, "__cudaPushCallConfiguration");

    kernel_launches++;
    log_ml_prediction(kernel_launches,
                      gridDim.x, gridDim.y, gridDim.z,
                      blockDim.x, blockDim.y, blockDim.z,
                      sharedMem);
    
    return real ? real(gridDim, blockDim, sharedMem, stream) : cudaSuccess;
}

cudaError_t __cudaPopCallConfiguration(dim3 *gridDim, dim3 *blockDim,
                                       size_t *sharedMem, void *stream) {
    typedef cudaError_t (*T)(dim3*, dim3*, size_t*, void*);
    static T real = NULL;
    if (!real) real = (T)dlsym(RTLD_NEXT, "__cudaPopCallConfiguration");
    return real ? real(gridDim, blockDim, sharedMem, stream) : cudaSuccess;
}

cudaError_t cudaLaunchKernel(const void *func,
                              dim3 gridDim, dim3 blockDim,
                              void **args, size_t sharedMem, cudaStream_t stream) {
    typedef cudaError_t (*T)(const void*, dim3, dim3, void**, size_t, cudaStream_t);
    static T real = NULL;
    if (!real) real = (T)dlsym(real_runtime ? real_runtime : RTLD_NEXT, "cudaLaunchKernel");
    
    return real(func, gridDim, blockDim, args, sharedMem, stream);
}
